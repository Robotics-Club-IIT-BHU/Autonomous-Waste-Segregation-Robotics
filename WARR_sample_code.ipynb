{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WARR sample code",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwS2ggW6RJ7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e32e927-ed6a-47c9-f638-e1614b2fa250"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmzQmZdKDfSF"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4TOw5rJs0M"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "width = 128\n",
        "height = 128\n",
        "epochs = 40\n",
        "NUM_TRAIN = 2000\n",
        "NUM_TEST = 1000\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpJ7Lc6GaHPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9636de7f-1e11-4c1f-e173-16238789e3e7"
      },
      "source": [
        "import cv2\n",
        "img=cv2.imread('train/0/67.jpg')\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IRZoPflv7fw"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnyJvYF_yXLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4c9ef2ab-3e5e-49c8-b086-cb372d1e20db"
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        "  !git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq00KoYUzOSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afcbbcef-f1d6-41d9-9203-768b86f4fa2e"
      },
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeETTKsszRj0"
      },
      "source": [
        "# loading pretrained conv base model\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=(64,64,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuA3LJlntSN7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b608978-e2f3-4e0f-83d1-25d5abc754d6"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6QB61j4y57R"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OdmlrfP40sc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be69892d-1bcb-4d8c-b63a-4ed38864c779"
      },
      "source": [
        "cd drive/My Drive/recognizance1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/recognizance1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBqtrHVu5iUE"
      },
      "source": [
        "\n",
        "\n",
        "# The directory where we will\n",
        "# store our smaller dataset\n",
        "# base_dir = './data/dog_vs_cat_small'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir ='train/'\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join('/', 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir ='test/'\n",
        "\n",
        "train_0_dir = 'train/0'\n",
        "# os.makedirs(train_0_dir, exist_ok=True)\n",
        "train_1_dir = 'train/1'\n",
        "# os.makedirs(train_1_dir, exist_ok=True)\n",
        "train_2_dir ='train/2'\n",
        "# os.makedirs(train_2_dir, exist_ok=True)\n",
        "train_3_dir = 'train/3'\n",
        "# os.makedirs(train_3_dir, exist_ok=True)\n",
        "train_4_dir = 'train/4'\n",
        "# os.makedirs(train_4_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "test_0_dir = 'test/0'\n",
        "# os.makedirs(validation_0_dir, exist_ok=True) \n",
        "test_1_dir = 'test/1'\n",
        "# os.makedirs(validation_1_dir, exist_ok=True)\n",
        "test_2_dir ='test/2'\n",
        "# os.makedirs(validation_2_dir, exist_ok=True)\n",
        "test_3_dir = 'test/3'\n",
        "# os.makedirs(validation_3_dir, exist_ok=True)\n",
        "test_4_dir ='test/4'\n",
        "# os.makedirs(validation_4_dir, exist_ok=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1jKkc_jgxWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3166c6e5-e61c-4eae-df7d-e166a87afedc"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample.csv  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtest1\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  train_label.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyD74zWe56WK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d2804edf-5462-4576-b043-36893f68df44"
      },
      "source": [
        "print('total training 0 images:', len(os.listdir(train_0_dir)))\n",
        "print('total training 1 images:', len(os.listdir(train_1_dir)))\n",
        "print('total training 2 images:', len(os.listdir(train_2_dir)))\n",
        "print('total training 3 images:', len(os.listdir(train_3_dir)))\n",
        "print('total training 4 images:', len(os.listdir(train_4_dir)))\n",
        "\n",
        "\n",
        "# print('total training 1 images:', len(os.listdir(train_1_dir)))\n",
        "print('total validation 0 images:', len(os.listdir('test/0')))\n",
        "print('total validation 1 images:', len(os.listdir('test/1')))\n",
        "\n",
        "print('total validation 2 images:', len(os.listdir('test/2')))\n",
        "print('total validation 3 images:', len(os.listdir('test/3')))\n",
        "\n",
        "print('total validation 4 images:', len(os.listdir('test/4')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training 0 images: 314\n",
            "total training 1 images: 120\n",
            "total training 2 images: 428\n",
            "total training 3 images: 279\n",
            "total training 4 images: 278\n",
            "total validation 0 images: 48\n",
            "total validation 1 images: 24\n",
            "total validation 2 images: 72\n",
            "total validation 3 images: 48\n",
            "total validation 4 images: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHa3B2bkFxaq"
      },
      "source": [
        "height=64\n",
        "width=64\n",
        "batch_size=64\n",
        "num_classes=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9MM2WA49zyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "32135e1e-aa28-474c-9b49-b4c82c808746"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=180,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to target height and width.\n",
        "        target_size=(height, width),\n",
        "        color_mode='grayscale',\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        color_mode='grayscale',\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1419 images belonging to 5 classes.\n",
            "Found 240 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3LaEc9fJTCW"
      },
      "source": [
        "Efficient net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgjoz26l-HfD"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(512,activation='relu',name=\"extra_dense\"))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(128,activation='relu',name=\"e_d_2\"))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(num_classes, activation='softmax', name=\"fc_out\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1nznF2EJUnq"
      },
      "source": [
        "Own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNRAsIEvIb7B"
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(16,(5,5),padding='valid',activation='relu',input_shape=(64,64,1)))\n",
        "model.add(layers.Conv2D(32,(5,5),padding='valid',activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(48,(3,3),activation='relu'))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "# model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(num_classes,activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iAX7AegDHUS"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-F9Z-uDJAi"
      },
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMjt8tCcDOoC"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)\n",
        "\n",
        "os.makedirs(\"./models\", exist_ok=True)\n",
        "model.save('./models/model01.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMYdtbTP66yV"
      },
      "source": [
        "!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!cp '/gdrive/My Drive/my_file' 'my_file'!!!!!!!!!!!!!!!!!!!!!!!dc124cs1d15c1d591d!cassaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaadgrgrggrv 33ewsdaasqdwdadasasdsac1# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvVt5TwoEDz6"
      },
      "source": [
        "os.makedirs(\"./models\", exist_ok=True)\n",
        "model.save('./models/model01.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLDHANW_HPVv"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path):\n",
        "    # Read the image and resize it\n",
        "    img = image.load_img(img_path, target_size=(height, width))\n",
        "    # Convert it to a Numpy array with target shape.\n",
        "    x = image.img_to_array(img)\n",
        "    # Reshape\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    x /= 255.\n",
        "    result = model.predict([x])[0][0]\n",
        "    return result\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}